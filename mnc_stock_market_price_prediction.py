# -*- coding: utf-8 -*-
"""MNC Stock-Market Price Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XiigfkJA2Ww_Uq1-kFA4uAvg4kRqoDc3
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
import math
import matplotlib.pyplot as plt
plt.style.use('fivethirtyeight')

# %matplotlib inline

from google.colab import files
files.upload()

"""### Understanding the Dataset

#### Metadata of the DataFrane
"""

stock_df_columns = ['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Name']
stock_df = pd.read_csv('IBM Stock Data.csv', names=stock_df_columns, skiprows=1)
stock_df.head()

stock_df.shape

stock_df.info()

stock_df['Date'] = pd.to_datetime(stock_df['Date'])

stock_df.info()

stock_df.isnull().sum()

stock_df['Open'] = stock_df['Open'].fillna(stock_df['Open'].mean())
stock_df['Low'] = stock_df['Low'].fillna(stock_df['Low'].mean())

stock_df.isnull().sum()

stock_df['Date'].max()

stock_df.set_index('Date', inplace=True)

stock_df.describe()

print(stock_df['Close'].min())
print(stock_df['Close'].max())

"""### Exploratory Data Analysis"""

plt.figure(figsize=(16,8))
plt.title('IBM')
plt.xlabel('Days')
plt.ylabel('Opening Price USD ($)')
plt.plot(stock_df['Open'])
plt.show()

plt.figure(figsize=(16,8))
plt.title('IBM')
plt.xlabel('Days')
plt.ylabel('High Price USD ($)')
plt.plot(stock_df['High'])
plt.show()

plt.figure(figsize=(16,8))
plt.title('IBM')
plt.xlabel('Days')
plt.ylabel('Lowest Price USD ($)')
plt.plot(stock_df['Low'])
plt.show()

plt.figure(figsize=(16,8))
plt.title('IBM')
plt.xlabel('Days')
plt.ylabel('Closing Price USD ($)')
plt.plot(stock_df['Close'])
plt.show()

sc = MinMaxScaler()

x_train = sc.fit_transform(stock_df.loc[:'2016'][['High', 'Low']])
y_train = stock_df.loc[:'2016']['Close']
x_test = sc.transform(stock_df.loc['2017':][['High', 'Low']])
y_test = stock_df.loc['2017':]['Close']
print("Train Data Shape :", x_train.shape)
print("Test Data Shape :", x_test.shape)

"""### Random Forest Regressor Model"""

from sklearn.ensemble import RandomForestRegressor
random_forest = RandomForestRegressor(n_estimators=200, random_state=40)

random_forest.fit(x_train, y_train)

y_test.head()

rf_plot_df = pd.DataFrame(y_test)
rf_plot_df.head()

predictions = random_forest.predict(x_test).reshape(-1,1)
rf_plot_df['Predictions'] = predictions
rf_plot_df.head()

plt.figure(figsize=(16,8))
plt.title('IBM Actual vs Prediction Closing Price')
plt.xlabel('Date')
plt.ylabel('Closing Price USD ($)')
plt.plot(rf_plot_df['Close'], color='blue', alpha=0.5, label="IBM Actual price")
plt.plot(rf_plot_df['Predictions'], color='orange', alpha=0.7, label="IBM Predicted Price")
plt.legend()
plt.show()

from sklearn.metrics import mean_squared_error
from math import sqrt

# assuming actual and pred are your data
rf_rmse = sqrt(mean_squared_error(rf_plot_df['Close'], rf_plot_df['Predictions']))

print("The root mean squared error is {}.".format(rf_rmse))

"""### Long Short-Term Memory Model"""

training_stock_df = stock_df.loc[:'2016'].iloc[:,1:2].values
test_stock_df = stock_df.loc['2017':].iloc[:,1:2].values

stock_df["High"][:'2016'].plot(figsize=(16,4),legend=True)
stock_df["High"]['2017':].plot(figsize=(16,4),legend=True)
plt.legend(['Training set (Before 2017)','Test set (2017 and beyond)'])
plt.title('IBM stock price')
plt.show()

sc = MinMaxScaler(feature_range=(0,1))
training_stock_df_scaled = sc.fit_transform(training_stock_df)

X_train = []
y_train = []
for i in range(60,len(training_stock_df_scaled)):
    X_train.append(training_stock_df_scaled[i-60:i,0])
    y_train.append(training_stock_df_scaled[i,0])
X_train, y_train = np.array(X_train), np.array(y_train)

X_train = np.reshape(X_train, (X_train.shape[0],X_train.shape[1],1))

from keras.models import Sequential
from keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional
from keras.optimizers import SGD

# The LSTM architecture
regressor = Sequential()
# First LSTM layer with Dropout regularisation
regressor.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1],1)))
regressor.add(Dropout(0.2))
# Second LSTM layer
regressor.add(LSTM(units=50, return_sequences=True))
regressor.add(Dropout(0.2))
# Third LSTM layer
regressor.add(LSTM(units=50, return_sequences=True))
regressor.add(Dropout(0.2))
# Fourth LSTM layer
regressor.add(LSTM(units=50))
regressor.add(Dropout(0.2))
# The output layer
regressor.add(Dense(units=1))

# Compiling the RNN
regressor.compile(optimizer='rmsprop',loss='mean_squared_error')
# Fitting to the training set
regressor.fit(X_train,y_train,epochs=50,batch_size=32)

dataset_total = pd.concat((stock_df["High"][:'2016'],stock_df["High"]['2017':]),axis=0)
inputs = dataset_total[len(dataset_total)-len(test_stock_df) - 60:].values
inputs = inputs.reshape(-1,1)
inputs  = sc.transform(inputs)

X_test = []
for i in range(60,311):
    X_test.append(inputs[i-60:i,0])
X_test = np.array(X_test)
X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))
lstm_predicted_stock_price = regressor.predict(X_test)
lstm_predicted_stock_price = sc.inverse_transform(lstm_predicted_stock_price)

plt.figure(figsize=(16,8))
plt.plot(test_stock_df, color='blue', alpha=0.5,label='Actual IBM Stock Price')
plt.plot(lstm_predicted_stock_price, color='orange', alpha=0.7,label='Predicted IBM Stock Price')
plt.title('IBM LSTM Stock Price Prediction')
plt.xlabel('Time')
plt.ylabel('IBM Stock Price')
plt.legend()
plt.show()

lstm_rmse = math.sqrt(mean_squared_error(test_stock_df, lstm_predicted_stock_price))
print("The root mean squared error is {}.".format(lstm_rmse))

"""### ARIMA

#### Understanding the distribution of the data
"""

stock_df['Close'].plot(kind='kde')

!pip install pmdarima

import warnings
warnings.filterwarnings('ignore')
from statsmodels.tsa.stattools import adfuller
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.arima.model import ARIMA
from pmdarima.arima import auto_arima
from sklearn.metrics import mean_absolute_error

def stationarityCheck(priceData):
    #Determing rolling statistics
    rolmean = priceData.rolling(12).mean()
    rolstd = priceData.rolling(12).std()
    #Plot rolling statistics:
    plt.plot(priceData, color='blue', alpha=0.5 ,label='Original')
    plt.plot(rolmean, color='red', alpha=0.5, label='Rolling Mean')
    plt.plot(rolstd, color='orange', label = 'Rolling Std')
    plt.legend(loc='best')
    plt.title('Rolling Mean and Standard Deviation')
    plt.show(block=False)

    print("Results of dickey fuller test")
    adft = adfuller(priceData,autolag='AIC')
    # output for dft will give us without defining what the values are.
    #hence we manually write what values does it explains using a for loop
    output = pd.Series(adft[0:4],index=['Test Statistics','p-value','No. of lags used','Number of observations used'])
    for key,values in adft[4].items():
        output['critical value (%s)'%key] =  values
    print(output)

stationarityCheck(stock_df['Close'])

"""#### Removing Trend and Seasonality from the Data"""

result = seasonal_decompose(stock_df['Close'], model='multiplicative', period = 30)
fig = plt.figure()
fig = result.plot()
fig.set_size_inches(16, 9)

"""#### Taking log values of the close price data to reduce magnitude of values and the trends in the series"""

stock_close_log_price = np.log(stock_df['Close'])
moving_avg = stock_close_log_price.rolling(12).mean()
std_dev = stock_close_log_price.rolling(12).std()
plt.legend(loc='best')
plt.title('Moving Average')
plt.plot(std_dev, color ="black", label = "Standard Deviation")
plt.plot(moving_avg, color="red", label = "Mean")
plt.legend()
plt.show()

train_data, test_data = stock_close_log_price[3:int(len(stock_close_log_price)*0.9)], stock_close_log_price[int(len(stock_close_log_price)*0.9):]
plt.figure(figsize=(10,6))
plt.grid(True)
plt.xlabel('Dates')
plt.ylabel('Closing Prices')
plt.plot(stock_close_log_price, 'blue', label='Train data')
plt.plot(test_data, 'red', label='Test data')
plt.legend()

model_autoARIMA = auto_arima(train_data, start_p=0, start_q=0,
                      test='adf',       # use adftest to find optimal 'd'
                      max_p=3, max_q=3, # maximum p and q
                      m=1,              # frequency of series
                      d=None,           # let model determine 'd'
                      seasonal=False,   # No Seasonality
                      start_P=0,
                      D=0,
                      trace=True,
                      error_action='ignore',
                      suppress_warnings=True,
                      stepwise=True)
print(model_autoARIMA.summary())
model_autoARIMA.plot_diagnostics(figsize=(15,8))
plt.show()

arima = ARIMA(train_data, order=(0,1,0))
fitted = arima.fit()
print(fitted.summary())

forecast_data = fitted.forecast(302, alpha=0.05)

forecast_data = forecast_data.reset_index(drop=True)
forecast_data

arima_plot_df = pd.DataFrame(test_data)
arima_plot_df.reset_index(inplace=True)
arima_plot_df['Predictions'] = forecast_data
arima_plot_df.set_index('Date', inplace=True)
arima_plot_df.head()

# Plot
plt.figure(figsize=(10,5), dpi=100)
plt.plot(train_data, label='training data')
plt.plot(arima_plot_df['Close'], color = 'blue', label='Actual Stock Price')
plt.plot(arima_plot_df['Predictions'], color = 'orange',label='Predicted Stock Price')
plt.title('IBM Stock Price Prediction')
plt.xlabel('Time')
plt.ylabel('IBM Stock Price')
plt.legend(loc='upper left', fontsize=8)
plt.show()

arima_rmse = sqrt(mean_squared_error(arima_plot_df['Close'], arima_plot_df['Predictions']))
print("The root mean squared error is {}.".format(arima_rmse))